# 처리율 제한 장치

## 1. 문제

### 서비스 구조
- Client: 모바일/웹 사용자 (좌석 조회 및 예매 요청)
- API Gateway: 모든 외부 요청이 통과하는 입구, 처리율 제한 장치를 두어야 함
- Application Server: 좌석 조회, 예매, 결제 등 비즈니스 로직 처리
- Redis Cluster: 분산 환경에서 공유 가능한 카운터 저장소
- Database: 좌석 및 예매 내역 최종 저장소

### 상황
- 특정 API(예매 요청)는 사용자별로 1분에 최대 60회 요청만 허용해야 한다.
- 인기 콘서트 예매 시, 한 사용자가 초당 수백 건의 요청을 보내고 있음.
- 단일 서버 환경에서는 In-Memory 기반 Rate Limiter로 동작했지만,
- 서버가 3대로 늘어나자 동일 사용자가 동시에 3대 서버에 요청을 보내며 제한이 무력화됨.

### 문제점
- in-Memory Counter는 서버별로 따로 유지 → 서버가 여러 대일 때 제한이 깨짐
-> 예: 3대 서버에서 각각 60회 허용 → 최대 180회까지 우회 가능
- Race Condition
-> 동시에 요청이 몰리면 Redis 카운터 증가/검증 시점 차이로 제한이 정확히 적용되지 않을 수 있음

위와 같은 문제점들을 정상적으로 처리할 수 있는 방법은??

## 2. 풀이

####  API Gateway + Redis Lua + Token Bucket 알고리즘
- Token Bucket 알고리즘 은 정확히 1분에 60번을 보장하지 않음
  - 짧은 시간동안 60번의 요청을 보내 토큰 소비를 하면 1초 뒤에 다시 토큰이 발급되기 때문
  - 만약 이를 막고 싶다면 버스트를 허용하지 않도록 설정 (혹은 슬라이딩 윈도 알고리즘 사용)
- Redis Lua를 사용하여 원자성을 보장하고 어플리케이션 앞단에 처리율 제한 장치를 위치 시켜 서버 분산 환경에도 적용
  - 클러스터링 환경에서는 Lua 스크립트의 모든 key가 같은 슬롯에 있어야 하기 때문에 키는 반드시 유저의 id 같은 hash tag를 사용
  - API 마다 다른 한도가 필요한 경우 **유저id:api명** 같이 API 마다 다른 키 생성 필요
